1. First I had copilot make me a very simple GO skeleton for json/csv reading, with testing prepared to get started right away. as well as make sure project can be run when pulled down easily. Added the decode.json and encodes.csv as well.
2. Next I gave a description to copilot regarding the data and my plan. focusing on this idea "Use JSON streaming decoder instead of loading all 10k records into memory" 
3. Following that planning I moved to seperate the functionality to readers and aggregators. along with their test files. Most of my time spent double checking code manually and making sure I was moving in the right direction.(Claude 4 was very effective here. creating the packages and testing. INCLUDING a relatively complete understanding of the aggregation. Commiting this work but plan to change it to a more dynamic approach.)
4. Next steps will include Testing review as there appear to be unmapped bitly encodes.
5. Added year filter. I prompted "next plan. I want to be able run a command in the the terminal that will run the aggregator with dynamic settings. First option. i want to be able to send a specific year and have it get the clicks for that year. it should default to 2021 if no year is sent." This is the Solution to the Project requirements. It can get all records for each Long URL for the year 2021 by default. As well as remaining dynamic, any year can be queried and 0 is ALL years.
