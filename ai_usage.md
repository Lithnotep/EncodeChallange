1. First I had copilot make me a very simple GO skeleton for json/csv reading, with testing prepared to get started right away. as well as make sure project can be run when pulled down easily. Added the decode.json and encodes.csv as well.
2. Next I gave a description to copilot regarding the data and my plan. focusing on this idea "Use JSON streaming decoder instead of loading all 10k records into memory" 
3. Following that planning I moved to seperate the functionality to readers and aggregators. along with their test files. Most of my time spent double checking code manually and making sure I was moving in the right direction.(Claude 4 was very effective here. creating the packages and testing. INCLUDING a relatively complete understanding of the aggregation. Commiting this work but plan to change it to a more dynamic approach.)
4. Next steps will include Testing review as there appear to be unmapped bitly encodes.

